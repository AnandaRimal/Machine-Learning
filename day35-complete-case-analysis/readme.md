# Complete Case Analysis (CCA)

## 1. Introduction
Missing data is a nightmare. The simplest (and most aggressive) way to handle it is **Complete Case Analysis (CCA)**, also known as "Listwise Deletion". It simply means: **Delete any row that has a missing value**. If a row isn't "complete", we ignore it.

![Illustration of rows with missing values being dropped from a table generated by Nano Banana Model](https://via.placeholder.com/800x400?text=CCA+Dropping+Rows+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### When to use CCA?
CCA is only safe to use if:
1.  **Data is Missing Completely At Random (MCAR)**: The missingness has no pattern and is unrelated to any other variable.
2.  **Missing data is small**: Usually, if less than 5% of the data is missing, CCA is acceptable.

**Missingness Taxonomy (Math/Concepts)**
- MCAR: $P(M=1\mid X,Y)=P(M=1)$; deletion unbiased but reduces power.
- MAR: $P(M=1\mid X,Y)=P(M=1\mid X)$; CCA can bias if missingness depends on observed features.
- MNAR: $P(M=1\mid Y)$; CCA often severely biased.

### The Risks
- **Data Loss**: If you have many columns with small amounts of missing data, you might end up deleting 50% of your rows.
- **Bias**: If the data is *not* MCAR (e.g., rich people refuse to share their salary), deleting those rows introduces bias.

## 3. Visualizing the Concept
*(Imagine a filter here generated by the Nano Banana Model: Rows with holes fall through the cracks, only solid rows remain)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `day35.ipynb` uses the `data_science_job.csv` dataset.

### 4.1 Identifying Candidates for CCA
We look for columns with < 5% missing data.
```python
cols = [var for var in df.columns if df[var].isnull().mean() < 0.05 and df[var].isnull().mean() > 0]
```

### 4.2 Dropping Rows
```python
new_df = df[cols].dropna()
```
We compare the shape of `df` vs `new_df` to see how much data we lost.

```python
loss = 1 - (len(new_df)/len(df))
print(f"Rows dropped: {loss:.2%}")
```

### 4.3 Verifying Distribution
**Crucial Step**: We must check if dropping rows changed the distribution of the data. We plot histograms of the original vs. the new data.
```python
# Overlay histograms
df['training_hours'].hist(color='red', density=True)
new_df['training_hours'].hist(color='green', density=True, alpha=0.8)
```
*Insight*: If the red and green histograms overlap perfectly, CCA was safe. If they diverge, we introduced bias.

```python
# Statistical test: compare means/variances
import scipy.stats as stats
print(stats.ttest_ind(df['training_hours'].dropna(), new_df['training_hours']))
```

## 5. Summary
CCA is the "nuclear option" for missing data. It's quick and easy, but use it with caution. Always verify that you haven't broken the statistical properties of your dataset.
 Prefer imputation when MAR/MNAR is suspected; if using CCA, quantify loss, test distributional shifts, and document rationale.

