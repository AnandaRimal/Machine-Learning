# Logistic Regression (Multiclass & Nonlinear)

## 1. Introduction
Building on binary logistic regression, we extend in two directions:
- **Multiclass (Softmax/One‑vs‑Rest)** classification for more than two classes.
- **Nonlinear decision boundaries** via polynomial feature engineering.

![Illustration of softmax probabilities across three classes and a curved boundary from polynomial features generated by Nano Banana Model](https://via.placeholder.com/800x400?text=Softmax+%2B+Nonlinear+Boundaries+by+Nano+Banana+Model)

## 2. Multiclass Logistic Regression

### One‑vs‑Rest (OvR)
Train one binary classifier per class vs all others; pick class with highest probability.

### Softmax (Multinomial)
Directly models all classes with a single objective.
$$ p(y=k|x) = \frac{e^{w_k^Tx}}{\sum_j e^{w_j^Tx}} $$
Optimizes cross‑entropy over all classes.

## 3. Nonlinear Boundaries via Features
Linear models can produce curved boundaries by augmenting inputs (e.g., $x^2, xy$). This keeps optimization convex but increases capacity.

## 4. Notebook Walkthroughs

### 4.1 Softmax Demo (`softmax-demo.ipynb`)
Shows probability vectors summing to 1 across classes and how decision boundaries shift with weights.

### 4.2 Polynomial Logistic (`polynomial-logistic-regression.ipynb`)
Using `PolynomialFeatures` to create curved boundaries:
```python
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LogisticRegression

model = make_pipeline(PolynomialFeatures(3), StandardScaler(with_mean=False),
					  LogisticRegression(max_iter=500, multi_class='auto'))
model.fit(X_train, y_train)
```

### 4.3 Streamlit Viz Tool (`streamlit-viz-tool.py`)
Interactive visualization of decision boundaries and probability maps.

## 5. Practical Tips
- Standardize features; logistic regression is sensitive to scale.
- Use regularization (`C` parameter) to prevent overfitting, especially with polynomial terms.
- Evaluate with ROC/PR for each class (micro/macro averaging).

## 6. Summary
Multinomial logistic regression handles multiple classes elegantly, and polynomial features add flexible, nonlinear boundaries—while preserving the simplicity and efficiency of linear models.

