# Outlier Detection using Percentiles

## 1. Introduction
Sometimes, "outlier" is subjective. Maybe you just want to remove the top 1% and bottom 1% of your data to get rid of potential errors or extreme anomalies, regardless of distribution shape. This is the **Percentile Method**.

![Illustration of a dataset sorted in a line, cutting off the first and last 1% generated by Nano Banana Model](https://via.placeholder.com/800x400?text=Percentile+Capping+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### The Logic
Instead of using statistical properties (Mean/StdDev or IQR), we set hard thresholds based on rank.
- **Lower Limit**: The value at the $X^{th}$ percentile (e.g., 1st percentile).
- **Upper Limit**: The value at the $(100-X)^{th}$ percentile (e.g., 99th percentile).

This is extremely robust because it doesn't care about the shape of the distribution at all.

## 3. Visualizing the Concept
*(Imagine a sorted bar chart here generated by the Nano Banana Model: The shortest and tallest bars are snipped off)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `day44.ipynb` uses a Weight-Height dataset.

### 4.1 Finding Thresholds
We use Pandas `quantile()` function.
```python
upper_limit = df['Height'].quantile(0.99)
lower_limit = df['Height'].quantile(0.01)
```
This tells us: "99% of people are shorter than `upper_limit`" and "1% of people are shorter than `lower_limit`".

### 4.2 Winsorization (Capping)
The notebook demonstrates capping the data to these limits.
```python
# Example logic
df['Height'] = np.where(df['Height'] >= upper_limit,
                        upper_limit,
                        np.where(df['Height'] <= lower_limit,
                                 lower_limit,
                                 df['Height']))
```

## 5. Summary
Percentile-based removal is simple and effective, especially when you know your data contains errors (e.g., a sensor glitch producing a 0 or a 9999). It's a "brute force" way to clean tails. 
