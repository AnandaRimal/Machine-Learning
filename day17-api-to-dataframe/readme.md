# API to DataFrame

## 1. Introduction
In the era of Big Data, static datasets are often insufficient. Data Scientists need access to real-time, dynamic data sources. **APIs (Application Programming Interfaces)** provide this access. This chapter focuses on the practical skill of querying a REST API, handling pagination, and constructing a robust dataset from scratch.

![Diagram showing the Request-Response cycle between a Client and a REST API generated by Nano Banana Model](https://via.placeholder.com/800x400?text=API+Request+Response+Cycle+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### The HTTP Protocol
APIs operate over HTTP. Key concepts include:
- **GET Request**: Retrieving data from a server.
- **Parameters**: Key-value pairs sent in the URL (e.g., `?page=1&api_key=xyz`) to filter or control the response.
- **Response Codes**: `200 OK` (Success), `404 Not Found`, `403 Forbidden`.

### Pagination
APIs rarely return all data in a single response to save bandwidth. Instead, they use **pagination**.
- **Page-based**: You request `page=1`, then `page=2`, etc.
- **Cursor-based**: The API gives you a token to fetch the "next" set of results.

### The Data Construction Loop
To build a complete dataset, we must:
1.  Initialize an empty container (DataFrame).
2.  Loop through pages.
3.  Fetch data -> Parse JSON -> Append to container.
4.  Handle errors and rate limits.

## 3. Visualizing the Concept
*(Imagine a flowchart here generated by the Nano Banana Model: Start -> Request Page 1 -> Parse JSON -> Append to List -> Is there a next page? -> Yes (Loop) / No (Finish) -> Convert to DataFrame)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `day17.ipynb` demonstrates building a dataset of **Top Rated Movies** using the TMDB (The Movie Database) API.

### 4.1 Setup and First Request
We start by importing `requests` and making a test call to understand the JSON structure.
```python
response = requests.get('https://api.themoviedb.org/3/movie/top_rated?api_key=YOUR_KEY&page=1')
temp_df = pd.DataFrame(response.json()['results'])
```
We extract specific columns like `id`, `title`, `overview`, `release_date`, `popularity`, `vote_average`, and `vote_count`.

### 4.2 The Pagination Loop
This is the core logic. We loop through 428 pages (the total available at the time) to fetch all movies.
```python
df = pd.DataFrame()
for i in range(1, 429):
    response = requests.get(f'https://api.themoviedb.org/3/movie/top_rated?api_key=...&page={i}')
    temp_df = pd.DataFrame(response.json()['results'])
    # Select columns and append
    df = df.append(temp_df, ignore_index=True)
```

### 4.3 Final Output
After the loop completes, we have a comprehensive DataFrame containing thousands of movies, which we save to `movies.csv`.

## 5. Summary
This module teaches the "Hunter-Gatherer" skill of Data Science. Instead of waiting for someone to give you a CSV, you go out to the web and create your own.
