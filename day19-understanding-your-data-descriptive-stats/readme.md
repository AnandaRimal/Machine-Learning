# Descriptive Statistics: Summarizing and Understanding Your Data

## 1. Introduction
Once data is loaded, the first step is not modeling, but **understanding**. Descriptive statistics provide a summary of the dataset's main characteristics. This chapter adds mathematical definitions, pros/cons, and robust code for summarizing distributions.

![Visualization of Mean, Median, and Mode distributions generated by Nano Banana Model](https://via.placeholder.com/800x400?text=Descriptive+Statistics+Visualization+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### The 5-Point Summary
For any numerical variable, we need to know:
1.  **Central Tendency**: Where is the center? (Mean, Median, Mode)
2.  **Dispersion**: How spread out is it? (Standard Deviation, Variance)
3.  **Shape**: Is it symmetrical? (Skewness, Kurtosis)

**Math**
- Mean: $\mu = \frac{1}{n}\sum x_i$; Median: middle value.
- Variance: $\sigma^2 = \frac{1}{n}\sum (x_i - \mu)^2$; Std: $\sigma = \sqrt{\sigma^2}$.
- Quantiles: $Q_p$ s.t. fraction $p$ below; IQR: $Q_{0.75} - Q_{0.25}$.
- Skewness: $\text{skew} = \frac{\frac{1}{n}\sum (x_i - \mu)^3}{\sigma^3}$; Kurtosis: $\frac{\frac{1}{n}\sum (x_i - \mu)^4}{\sigma^4}$.

### Data Types (Dtypes)
Understanding types is crucial:
- **Numerical**: Continuous (Height) or Discrete (Count).
- **Categorical**: Nominal (Color) or Ordinal (Rank).
- **Datetime**: Time-series data.

### Missingness
Data is rarely perfect. We must quantify **Null** values to decide on imputation strategies later.

**Pros/Cons**
- Pros: Fast health-check; reveals outliers and scale; guides preprocessing.
- Cons: Aggregates hide multimodality; mean/variance sensitive to outliers; correlations can be misleading without stratification.

## 3. Visualizing the Concept
*(Imagine a dashboard here generated by the Nano Banana Model showing histograms, box plots, and summary tables for a dataset)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `day19.ipynb` uses the **Titanic** dataset to demonstrate these concepts.

### 4.1 High-Level Overview
```python
df.shape  # (Rows, Columns)
df.head() # First 5 rows
df.sample(5) # Random 5 rows (crucial for checking bias)
```

### 4.2 Data Health Check (`info`)
The `df.info()` function is the MRI of your dataframe.
```python
df.info()
```
It reveals:
- Missing values (Non-Null count).
- Data types (int64, float64, object).
- Memory usage.

### 4.3 Mathematical Summary (`describe`)
```python
df.describe()
```
This outputs the count, mean, std, min, 25%, 50%, 75%, and max for all numerical columns. It helps spot outliers (e.g., if max Age is 200).

```python
num = df.select_dtypes('number')
metrics = {
	'skew': num.skew(),
	'kurt': num.kurtosis(),
	'iqr': num.quantile(0.75) - num.quantile(0.25)
}
print(metrics['skew'].sort_values())
```

### 4.4 Correlation Analysis
```python
df.corr()['Survived']
```
We check how features relate to the target.
- **Positive Correlation**: As X increases, Y increases.
- **Negative Correlation**: As X increases, Y decreases.

```python
corr = num.corr(method='pearson')
strong = corr.abs().stack().sort_values(ascending=False)
print(strong.head(10))
```

### 4.5 Categorical Analysis
For non-numerical columns, we use `value_counts()` to see the frequency distribution.
```python
df['Embarked'].value_counts()
```

## 5. Summary
Descriptive statistics are the "vital signs" of your data. Quantify center, spread, and shape; visualize distributions; and audit missingness to guide imputation, scaling, and outlier handling.
