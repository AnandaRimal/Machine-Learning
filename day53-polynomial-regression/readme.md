# Polynomial Regression

## 1. Introduction
Linear Regression fits a straight line. But what if your data is curved? Like the trajectory of a ball or the growth of a virus?
**Polynomial Regression** is a hack: we don't change the model (it's still Linear Regression); we change the **data**. By adding powers of the original features ($x^2, x^3$), we can fit complex curves.

![Illustration of a curve fitting through parabolic data points compared to a straight line missing them generated by Nano Banana Model](https://via.placeholder.com/800x400?text=Polynomial+Regression+Curve+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### The Trick
The equation for a line is $y = m x + b$.
The equation for a parabola is $y = m_1 x + m_2 x^2 + b$.
Notice something? It's still a linear combination of coefficients ($m_1, m_2$).
If we treat $x^2$ as just another feature (let's call it $z$), the equation becomes $y = m_1 x + m_2 z + b$.
This is just **Multiple Linear Regression**!

### Bias-Variance Tradeoff
- **Degree 1 (Line)**: High Bias (Underfitting).
- **Degree 2 (Parabola)**: Good fit.
- **Degree 20 (Wiggle)**: High Variance (Overfitting). It touches every point but fails on new data.

## 3. Visualizing the Concept
*(Imagine a straight line trying to fit a U-shape (failing), then bending into a U-shape (fitting), then becoming a crazy scribble (overfitting) generated by the Nano Banana Model)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `polynomial-regression.ipynb` generates synthetic non-linear data ($y = 0.8x^2 + ...$).

### 4.1 Generating Non-Linear Data
```python
X = 6 * np.random.rand(200, 1) - 3
y = 0.8 * X**2 + 0.9 * X + 2 + noise
```

### 4.2 Polynomial Features
We use Scikit-Learn's `PolynomialFeatures` to create the squared terms.
```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X_train)
```
If `X` was `[2]`, `X_poly` becomes `[1, 2, 4]` (Bias, $x$, $x^2$).

### 4.3 Training
We then feed this transformed data into a standard Linear Regression model.
```python
lr = LinearRegression()
lr.fit(X_poly, y_train)
```
The result is a beautiful curve that fits the data perfectly.

## 5. Summary
Polynomial Regression is a powerful tool to model non-linear relationships without needing complex algorithms. It's simply Linear Regression on steroids (feature engineering).

