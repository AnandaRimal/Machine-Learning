# Handling Date and Time - Temporal Feature Engineering\n\n## General Idea\n\nDate and time variables contain temporal information that cannot be directly used by machine learning algorithms in their raw format. Handling dates and times involves extracting meaningful features (year, month, day, hour, cyclical components, time differences) and creating derived temporal features that capture patterns, seasonality, and time-based relationships. Proper datetime handling is crucial for time-series analysis, forecasting, and any dataset where temporal patterns matter.\n\n## Why Handle Dates and Times?\n\n1. **Not Directly Usable**: ML models need numeric input, not \"2023-05-15\"\n2. **Rich Information**: Dates contain year, month, day, day of week, etc.\n3. **Temporal Patterns**: Seasonality, trends, cyclical behavior\n4. **Time-Based Features**: Age, duration, time since event\n5. **Business Logic**: Weekends vs weekdays, holidays, quarters\n6. **Relationships**: Time differences, time until deadline\n7. **Cyclical Nature**: Hour 23 is close to hour 0 (needs special encoding)\n8. **Improve Predictions**: Temporal features often highly predictive\n\n## Role in Machine Learning\n\n### Temporal Patterns\n\nMany phenomena have time-based patterns:\n\n**Seasonality**:\n- Ice cream sales: High in summer, low in winter\n- Feature: month \u2192 captures seasonal effect\n\n**Day-of-Week Effects**:\n- Website traffic: Lower on weekends\n- Feature: day_of_week \u2192 captures weekly patterns\n\n**Hour-of-Day Effects**:\n- Energy usage: Peak in evening\n- Feature: hour \u2192 captures daily cycles\n\n**Trends**:\n- Customer growth over time\n- Feature: days_since_launch \u2192 captures trend\n\n**Mathematical representation**:\n$$y = f(\\text{features}, \\text{temporal\\_features})$$\n\nWhere temporal features $\\in$ {year, month, day, hour, day_of_week, ...}\n\n### Time-Series vs Cross-Sectional\n\n**Time-Series Data**: Observations over time for same entity\n- Stock prices: AAPL daily closing price\n- Temperature: Hourly readings from sensor\n- **Key**: Temporal order matters, autocorrelation\n\n**Cross-Sectional with Dates**: Snapshot at different times\n- Customer transactions: Many customers, various dates\n- Loan applications: Different people, different application dates\n- **Key**: Date is a feature, not necessarily ordered\n\n**Both benefit** from datetime feature engineering\n\n## Types of Datetime Features\n\n### 1. Component Extraction\n\n**From a datetime**: Extract individual components\n\n**Date Components**:\n- **Year**: 2023, 2024, ...\n- **Month**: 1 (Jan) to 12 (Dec)\n- **Day**: 1 to 31\n- **Day of Week**: 0 (Monday) to 6 (Sunday)\n- **Day of Year**: 1 to 365/366\n- **Week of Year**: 1 to 52/53\n- **Quarter**: 1 (Q1) to 4 (Q4)\n\n**Time Components** (if timestamp):\n- **Hour**: 0 to 23\n- **Minute**: 0 to 59\n- **Second**: 0 to 59\n\n**Example**:\n```python\ndate = pd.Timestamp('2023-05-15 14:30:00')\n\nfeatures = {\n    'year': date.year,         # 2023\n    'month': date.month,       # 5\n    'day': date.day,           # 15\n    'dayofweek': date.dayofweek,  # 0 (Monday)\n    'hour': date.hour,         # 14\n    'minute': date.minute,     # 30\n    'quarter': date.quarter    # 2 (Q2)\n}\n```\n\n**Use cases**:\n- Capture seasonality (month, quarter)\n- Weekday/weekend patterns (day_of_week)\n- Daily cycles (hour)\n- Long-term trends (year)\n\n### 2. Derived Binary Indicators\n\n**Boolean features** indicating special conditions:\n\n**Is Weekend**:\n$$\\text{is\\_weekend} = \\mathbb{1}_{\\text{dayofweek} \\in \\{5, 6\\}}$$\n\n**Is Month End**:\n$$\\text{is\\_month\\_end} = \\mathbb{1}_{\\text{day} = \\text{last\\_day\\_of\\_month}}$$\n\n**Is Quarter End**:\n$$\\text{is\\_quarter\\_end} = \\mathbb{1}_{\\text{month} \\in \\{3, 6, 9, 12\\} \\land \\text{is\\_month\\_end}}$$\n\n**Is Holiday**:\n$$\\text{is\\_holiday} = \\mathbb{1}_{\\text{date} \\in \\text{holiday\\_list}}$$\n\n**Business Day**:\n$$\\text{is\\_business\\_day} = \\mathbb{1}_{\\text{dayofweek} < 5 \\land \\text{not holiday}}$$\n\n**Example**:\n```python\ndf['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6]).astype(int)\ndf['is_month_end'] = df['date'].dt.is_month_end.astype(int)\ndf['is_quarter_end'] = df['date'].dt.is_quarter_end.astype(int)\n```\n\n### 3. Time Since/Until Features\n\n**Elapsed time** from reference point:\n\n**Days Since Event**:\n$$\\text{days\\_since\\_signup} = (\\text{current\\_date} - \\text{signup\\_date}).\\text{days}$$\n\n**Age Calculation**:\n$$\\text{age} = (\\text{current\\_date} - \\text{birth\\_date}).\\text{years}$$\n\n**Days Until Deadline**:\n$$\\text{days\\_until\\_deadline} = (\\text{deadline\\_date} - \\text{current\\_date}).\\text{days}$$\n\n**Tenure**:\n$$\\text{customer\\_tenure} = (\\text{current\\_date} - \\text{first\\_purchase\\_date}).\\text{days}$$\n\n**Example**:\n```python\ndf['customer_age_days'] = (pd.Timestamp.now() - df['signup_date']).dt.days\ndf['account_age_years'] = df['customer_age_days'] / 365.25\n```\n\n**Why useful**: \n- Captures \"freshness\" (new vs old customers)\n- Urgency (time until deadline)\n- Lifecycle stage (tenure-based behaviors)\n\n### 4. Time Differences Between Events\n\n**Duration** between two dates:\n\n**Time to Convert**:\n$$\\text{days\\_to\\_convert} = (\\text{purchase\\_date} - \\text{first\\_visit\\_date}).\\text{days}$$\n\n**Loan Duration**:\n$$\\text{loan\\_duration\\_months} = (\\text{loan\\_end\\_date} - \\text{loan\\_start\\_date}).\\text{months}$$\n\n**Response Time**:\n$$\\text{response\\_hours} = (\\text{response\\_time} - \\text{inquiry\\_time}).\\text{hours}$$\n\n**Example**:\n```python\ndf['purchase_lag'] = (df['purchase_date'] - df['signup_date']).dt.days\ndf['campaign_duration'] = (df['end_date'] - df['start_date']).dt.days\n```\n\n### 5. Cyclical Features (Sin/Cos Encoding)\n\n**Problem**: Month 12 (December) is close to month 1 (January), but numerically $|12 - 1| = 11$ (far)\n\n**Solution**: Encode cyclical features using sine and cosine\n\n**Mathematical transformation**:\n$$\\text{month\\_sin} = \\sin\\left(\\frac{2\\pi \\cdot \\text{month}}{12}\\right)$$\n$$\\text{month\\_cos} = \\cos\\left(\\frac{2\\pi \\cdot \\text{month}}{12}\\right)$$\n\n**General formula** for cyclical feature with period $P$:\n$$x_{\\text{sin}} = \\sin\\left(\\frac{2\\pi \\cdot x}{P}\\right)$$\n$$x_{\\text{cos}} = \\cos\\left(\\frac{2\\pi \\cdot x}{P}\\right)$$\n\n**Common cyclical features**:\n- **Month**: $P = 12$\n- **Day of week**: $P = 7$\n- **Hour**: $P = 24$\n- **Day of year**: $P = 365$\n\n**Example**:\n```python\ndf['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\ndf['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n\ndf['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\ndf['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n```\n\n**Why it works**: \n- December (12): $\\sin(2\\pi) \\approx 0$, $\\cos(2\\pi) \\approx 1$\n- January (1): $\\sin(2\\pi/12) \\approx 0.5$, $\\cos(2\\pi/12) \\approx 0.87$\n- Distance in $(\\sin, \\cos)$ space is small (geometrically close)\n\n**Visualization**: Points on a circle\n- Months map to points on unit circle\n- December and January are adjacent on circle\n\n### 6. Aggregated Temporal Features\n\n**Statistics** over time windows:\n\n**Rolling Mean**:\n$$\\text{sales\\_7day\\_avg} = \\frac{1}{7}\\sum_{i=0}^{6} \\text{sales}_{t-i}$$\n\n**Lag Features** (previous values):\n$$\\text{sales\\_lag1} = \\text{sales}_{t-1}$$\n$$\\text{sales\\_lag7} = \\text{sales}_{t-7}$$\n\n**Time Since Last Event**:\n$$\\text{days\\_since\\_last\\_purchase} = t - \\max(t_i : \\text{purchase}_i = 1)$$\n\n**Example**:\n```python\n# Rolling statistics\ndf['sales_7day_mean'] = df['sales'].rolling(window=7).mean()\ndf['sales_30day_std'] = df['sales'].rolling(window=30).std()\n\n# Lag features\ndf['sales_lag1'] = df['sales'].shift(1)\ndf['sales_lag7'] = df['sales'].shift(7)\n\n# Time since last event\nlast_purchase = df[df['purchased'] == 1].groupby('customer_id')['date'].max()\ndf['days_since_purchase'] = (df['date'] - df['customer_id'].map(last_purchase)).dt.days\n```\n\n## Pandas Datetime Handling\n\n### Parsing Dates\n\n**Convert string to datetime**:\n```python\nimport pandas as pd\n\n# Automatic parsing\ndf['date'] = pd.to_datetime(df['date_string'])\n\n# Specify format for speed\ndf['date'] = pd.to_datetime(df['date_string'], format='%Y-%m-%d')\n\n# Handle errors\ndf['date'] = pd.to_datetime(df['date_string'], errors='coerce')  # Invalid -> NaT\n```\n\n**Common formats**:\n- `'%Y-%m-%d'`: 2023-05-15\n- `'%m/%d/%Y'`: 05/15/2023\n- `'%d-%b-%Y'`: 15-May-2023\n- `'%Y-%m-%d %H:%M:%S'`: 2023-05-15 14:30:00\n\n### Accessing Components\n\n**Using .dt accessor**:\n```python\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\ndf['dayofweek'] = df['date'].dt.dayofweek\ndf['dayofyear'] = df['date'].dt.dayofyear\ndf['quarter'] = df['date'].dt.quarter\ndf['weekofyear'] = df['date'].dt.isocalendar().week\n```\n\n**For timestamps**:\n```python\ndf['hour'] = df['timestamp'].dt.hour\ndf['minute'] = df['timestamp'].dt.minute\ndf['second'] = df['timestamp'].dt.second\n```\n\n### Date Arithmetic\n\n**Difference between dates**:\n```python\ndf['duration'] = df['end_date'] - df['start_date']  # Timedelta\ndf['duration_days'] = df['duration'].dt.days\ndf['duration_seconds'] = df['duration'].dt.total_seconds()\n```\n\n**Add/subtract time**:\n```python\ndf['next_week'] = df['date'] + pd.Timedelta(days=7)\ndf['last_month'] = df['date'] - pd.DateOffset(months=1)\n```\n\n## Scikit-Learn Integration\n\n### Custom Transformer for Datetime Features\n\n```python\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\nimport numpy as np\n\nclass DatetimeFeatureExtractor(BaseEstimator, TransformerMixin):\n    def __init__(self, date_column, drop_original=True):\n        self.date_column = date_column\n        self.drop_original = drop_original\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        \n        # Ensure datetime type\n        if not pd.api.types.is_datetime64_any_dtype(X[self.date_column]):\n            X[self.date_column] = pd.to_datetime(X[self.date_column])\n        \n        # Extract components\n        X['year'] = X[self.date_column].dt.year\n        X['month'] = X[self.date_column].dt.month\n        X['day'] = X[self.date_column].dt.day\n        X['dayofweek'] = X[self.date_column].dt.dayofweek\n        X['quarter'] = X[self.date_column].dt.quarter\n        X['dayofyear'] = X[self.date_column].dt.dayofyear\n        \n        # Binary indicators\n        X['is_weekend'] = (X['dayofweek'] >= 5).astype(int)\n        X['is_month_start'] = X[self.date_column].dt.is_month_start.astype(int)\n        X['is_month_end'] = X[self.date_column].dt.is_month_end.astype(int)\n        X['is_quarter_end'] = X[self.date_column].dt.is_quarter_end.astype(int)\n        \n        # Cyclical encoding\n        X['month_sin'] = np.sin(2 * np.pi * X['month'] / 12)\n        X['month_cos'] = np.cos(2 * np.pi * X['month'] / 12)\n        X['dayofweek_sin'] = np.sin(2 * np.pi * X['dayofweek'] / 7)\n        X['dayofweek_cos'] = np.cos(2 * np.pi * X['dayofweek'] / 7)\n        \n        # Drop original if specified\n        if self.drop_original:\n            X = X.drop(columns=[self.date_column])\n        \n        return X\n```\n\n### Using in Pipeline\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\npipeline = Pipeline([\n    ('datetime_features', DatetimeFeatureExtractor(date_column='purchase_date')),\n    ('scaler', StandardScaler()),\n    ('model', LinearRegression())\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)\n```\n\n### With ColumnTransformer\n\n```python\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Custom function for datetime\ndef extract_datetime_features(X):\n    df = pd.DataFrame(X, columns=['date'])\n    df['date'] = pd.to_datetime(df['date'])\n    \n    features = pd.DataFrame({\n        'year': df['date'].dt.year,\n        'month': df['date'].dt.month,\n        'day': df['date'].dt.day,\n        'dayofweek': df['date'].dt.dayofweek,\n        'is_weekend': (df['date'].dt.dayofweek >= 5).astype(int)\n    })\n    return features.values\n\npreprocessor = ColumnTransformer([\n    ('datetime', FunctionTransformer(extract_datetime_features), ['purchase_date']),\n    ('numeric', StandardScaler(), numeric_features),\n    ('categorical', OneHotEncoder(), categorical_features)\n])\n\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression())\n])\n```\n\n## Practical Examples\n\n### Example 1: Customer Transaction Data\n\n**Dataset**: customer_id, transaction_date, amount\n\n**Goal**: Predict customer churn\n\n**Datetime features**:\n```python\n# Recency: Days since last transaction\ndf['days_since_transaction'] = (pd.Timestamp.now() - df['transaction_date']).dt.days\n\n# Frequency components\ndf['transaction_month'] = df['transaction_date'].dt.month\ndf['transaction_quarter'] = df['transaction_date'].dt.quarter\ndf['is_weekend_transaction'] = (df['transaction_date'].dt.dayofweek >= 5).astype(int)\n\n# Seasonality (cyclical)\ndf['month_sin'] = np.sin(2 * np.pi * df['transaction_month'] / 12)\ndf['month_cos'] = np.cos(2 * np.pi * df['transaction_month'] / 12)\n```\n\n**Why these features**:\n- days_since_transaction: Recent activity indicates engagement\n- month/quarter: Seasonal spending patterns\n- is_weekend: Different behavior on weekends\n- Cyclical month: Captures year-end vs mid-year patterns\n\n### Example 2: Energy Consumption Forecasting\n\n**Dataset**: timestamp, energy_kwh\n\n**Goal**: Forecast hourly energy usage\n\n**Datetime features**:\n```python\ndf['hour'] = df['timestamp'].dt.hour\ndf['dayofweek'] = df['timestamp'].dt.dayofweek\ndf['month'] = df['timestamp'].dt.month\n\n# Cyclical encoding\ndf['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\ndf['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n\n# Binary indicators\ndf['is_business_hour'] = ((df['hour'] >= 9) & (df['hour'] <= 17)).astype(int)\ndf['is_weekday'] = (df['dayofweek'] < 5).astype(int)\n\n# Lag features\ndf['energy_lag1'] = df['energy_kwh'].shift(1)   # Previous hour\ndf['energy_lag24'] = df['energy_kwh'].shift(24) # Same hour yesterday\n\n# Rolling mean\ndf['energy_24h_avg'] = df['energy_kwh'].rolling(window=24).mean()\n```\n\n**Why these features**:\n- hour: Daily cycle (peak evening usage)\n- dayofweek: Weekday vs weekend patterns\n- is_business_hour: Commercial usage\n- Lags: Autocorrelation in time series\n- Rolling mean: Smooth short-term trends\n\n### Example 3: Loan Default Prediction\n\n**Dataset**: loan_id, application_date, birth_date, loan_amount\n\n**Goal**: Predict loan default\n\n**Datetime features**:\n```python\n# Age at application\ndf['age'] = (df['application_date'] - df['birth_date']).dt.days / 365.25\n\n# Application timing\ndf['application_month'] = df['application_date'].dt.month\ndf['application_dayofweek'] = df['application_date'].dt.dayofweek\ndf['is_year_end'] = (df['application_month'] == 12).astype(int)\n\n# Seasonality\ndf['month_sin'] = np.sin(2 * np.pi * df['application_month'] / 12)\ndf['month_cos'] = np.cos(2 * np.pi * df['application_month'] / 12)\n```\n\n**Why these features**:\n- age: Key predictor of financial stability\n- application_month: Seasonal lending patterns\n- is_year_end: Year-end financial stress\n- Cyclical month: Tax season, holiday spending\n\n## Best Practices\n\n### 1. Parse Dates Early\n\n**At data loading**:\n```python\ndf = pd.read_csv('data.csv', parse_dates=['date_column'])\n```\n\n**Benefits**: \n- Automatic type detection\n- Faster subsequent operations\n- Easier to work with\n\n### 2. Handle Missing Dates\n\n**Check for NaT** (Not-a-Time):\n```python\nprint(df['date'].isna().sum())\n```\n\n**Strategies**:\n- **Drop**: If few missing\n- **Forward fill**: For time series\n- **Backward fill**: For specific use cases\n- **Impute with mode**: For cross-sectional\n\n```python\ndf['date'] = df['date'].fillna(method='ffill')  # Forward fill\n```\n\n### 3. Be Careful with Time Zones\n\n**Specify timezone**:\n```python\ndf['date'] = pd.to_datetime(df['date'], utc=True)\ndf['date'] = df['date'].dt.tz_convert('America/New_York')\n```\n\n**Why important**: Avoid ambiguous times, consistent comparisons\n\n### 4. Use Cyclical Encoding for Periodic Features\n\n**Don't**: Use month as 1-12 directly (implies December far from January)\n\n**Do**: Use sin/cos encoding\n\n**Especially important for**: Neural networks, linear models\n\n**Less important for**: Tree-based models (can split on both sides)\n\n### 5. Create Domain-Relevant Features\n\n**E-commerce**: is_black_friday, is_cyber_monday, days_to_christmas\n\n**Finance**: is_quarter_end, days_to_earnings, tax_season\n\n**Retail**: is_weekend, is_holiday, week_of_month\n\n**Incorporate domain knowledge** into feature engineering\n\n### 6. Avoid Leakage with Future Information\n\n**Wrong**: Using information from the future\n```python\n# If predicting sales on day t\ndf['next_week_sales'] = df['sales'].shift(-7)  # Leakage!\n```\n\n**Right**: Only use past information\n```python\ndf['last_week_sales'] = df['sales'].shift(7)  # Okay\n```\n\n### 7. Standardize Datetime Formats\n\n**Consistent format** across dataset:\n```python\ndf['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n```\n\n**Benefits**: Faster parsing, error detection\n\n### 8. Validate Extracted Features\n\n**Sanity checks**:\n```python\nassert df['month'].between(1, 12).all()\nassert df['dayofweek'].between(0, 6).all()\nassert df['hour'].between(0, 23).all()\n```\n\n### 9. Consider Feature Interactions\n\n**Example**: weekend Ã— hour interaction\n```python\ndf['weekend_evening'] = ((df['is_weekend'] == 1) & (df['hour'] >= 18)).astype(int)\n```\n\n**Captures**: Unique weekend evening behavior\n\n### 10. Document Temporal Feature Meaning\n\n**Clear naming**:\n- `days_since_signup` (not `d_s`)\n- `is_month_end` (not `me`)\n- `transaction_quarter` (not `q`)\n\n**Comments**: Explain business logic\n\n## Common Patterns\n\n### Pattern 1: RFM Features (Recency, Frequency, Monetary)\n\n```python\n# Recency: Days since last transaction\ndf['recency'] = (pd.Timestamp.now() - df.groupby('customer_id')['date'].transform('max')).dt.days\n\n# Frequency: Count of transactions in time window\ndf['frequency_30d'] = df.groupby('customer_id')['date'].transform(\n    lambda x: ((pd.Timestamp.now() - x).dt.days <= 30).sum()\n)\n\n# Monetary: Total spend in time window\ndf['monetary_30d'] = df[df['date'] >= pd.Timestamp.now() - pd.Timedelta(days=30)].groupby('customer_id')['amount'].transform('sum')\n```\n\n### Pattern 2: Time-Series Lag and Rolling Features\n\n```python\n# Lags\nfor lag in [1, 7, 30]:\n    df[f'sales_lag{lag}'] = df['sales'].shift(lag)\n\n# Rolling statistics\nfor window in [7, 30]:\n    df[f'sales_{window}d_mean'] = df['sales'].rolling(window).mean()\n    df[f'sales_{window}d_std'] = df['sales'].rolling(window).std()\n```\n\n### Pattern 3: Holiday and Special Event Indicators\n\n```python\nimport holidays\n\nus_holidays = holidays.US()\ndf['is_holiday'] = df['date'].apply(lambda x: x in us_holidays).astype(int)\n\n# Custom events\nblack_friday_2023 = pd.Timestamp('2023-11-24')\ndf['is_black_friday'] = (df['date'] == black_friday_2023).astype(int)\ndf['days_to_black_friday'] = (black_friday_2023 - df['date']).dt.days\n```\n\n### Pattern 4: Customer Lifecycle Features\n\n```python\n# Account age\nfirst_purchase = df.groupby('customer_id')['purchase_date'].transform('min')\ndf['customer_age_days'] = (df['purchase_date'] - first_purchase).dt.days\n\n# Lifecycle stage\ndf['lifecycle_stage'] = pd.cut(\n    df['customer_age_days'],\n    bins=[0, 30, 90, 365, np.inf],\n    labels=['New', 'Active', 'Established', 'Loyal']\n)\n```\n\n## Summary\n\nHandling dates and times is a critical preprocessing step that transforms temporal information into meaningful numeric features capturing seasonality, trends, and time-based relationships.\n\n**Key Concepts**:\n\n**Datetime Components**:\n- Basic: year, month, day, hour, minute\n- Derived: day_of_week, quarter, day_of_year\n- Binary: is_weekend, is_holiday, is_month_end\n\n**Feature Types**:\n1. **Component extraction**: month, day, hour\n2. **Binary indicators**: is_weekend, is_holiday\n3. **Time since/until**: days_since_signup, age\n4. **Durations**: time_between_events\n5. **Cyclical encoding**: sin/cos for periodic features\n6. **Aggregations**: rolling mean, lag features\n\n**Cyclical Encoding** (for periodic features):\n$$x_{\\text{sin}} = \\sin\\left(\\frac{2\\pi \\cdot x}{\\text{period}}\\right)$$\n$$x_{\\text{cos}} = \\cos\\left(\\frac{2\\pi \\cdot x}{\\text{period}}\\right)$$\n\n**Pandas Tools**:\n- `pd.to_datetime()`: Parse dates\n- `.dt` accessor: Extract components\n- Date arithmetic: Differences, offsets\n- Rolling/shifting: Time-series features\n\n**sklearn Integration**:\n- Custom transformers: DatetimeFeatureExtractor\n- FunctionTransformer: Quick extraction\n- ColumnTransformer: Combine with other preprocessing\n\n**Best Practices**:\n- Parse dates early\n- Handle missing dates\n- Use cyclical encoding for periodic features\n- Create domain-relevant features\n- Avoid future information leakage\n- Validate extracted features\n- Document feature meaning\n\n**Common Patterns**:\n- RFM features (recency, frequency, monetary)\n- Time-series lags and rolling statistics\n- Holiday/event indicators\n- Customer lifecycle features\n\n**Applications**:\n- Time-series forecasting: energy, sales, demand\n- Customer analytics: churn, lifetime value\n- Fraud detection: transaction timing patterns\n- Operations: staffing, inventory optimization\n\n**Result**: Rich temporal features that capture time-based patterns, improving model performance for datasets where \"when\" matters as much as \"what\".\n\nProper datetime handling is essential for leveraging temporal information in machine learning, enabling models to learn seasonality, trends, and time-dependent behaviors that drive predictions.\n\n---\n\n**Video Link**: https://youtu.be/J73mvgG9fFs"
