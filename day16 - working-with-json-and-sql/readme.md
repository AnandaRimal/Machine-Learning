# Working with JSON and SQL

## 1. Introduction
In the modern data ecosystem, data rarely lives in isolation. It flows from Web APIs in **JSON** format and resides in robust **SQL** databases. This chapter explores how to bridge the gap between these storage formats and the analytical power of Pandas DataFrames.

![Illustration of JSON hierarchical structure vs SQL tabular structure generated by Nano Banana Model](https://via.placeholder.com/800x400?text=JSON+vs+SQL+Structure+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### JSON (JavaScript Object Notation)
JSON is the standard format for data interchange on the web. Unlike the flat, row-column structure of CSVs, JSON is **hierarchical** and **semi-structured**.
- **Key-Value Pairs**: Data is stored as `key: value`.
- **Nesting**: Values can be lists or other objects, creating a tree-like structure.

### SQL (Structured Query Language)
SQL databases (MySQL, PostgreSQL) store data in **relational tables** with strict schemas.
- **ACID Properties**: Ensures data integrity.
- **Relationships**: Tables are linked via Foreign Keys.

### The ETL Process
The notebook in this folder performs a mini-ETL (Extract, Transform, Load) process:
1.  **Extract**: Pull data from a JSON file or SQL database.
2.  **Transform**: Convert nested JSON or SQL result sets into a flat Pandas DataFrame.
3.  **Load**: Ready for analysis.

## 3. Visualizing the Concept
*(Imagine a diagram here generated by the Nano Banana Model showing a tree structure (JSON) being flattened into a 2D matrix (DataFrame), and a SQL query pipeline feeding into a DataFrame)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `day16.ipynb` covers two distinct sections:

### 4.1 Working with JSON
We use `pd.read_json()` to handle JSON data.

**Loading Local JSON:**
```python
import pandas as pd
df = pd.read_json('train.json')
```
This reads a local file. Pandas automatically infers the orientation (records, columns, index).

**Loading from URL (API):**
```python
df = pd.read_json('https://api.exchangerate-api.com/v4/latest/INR')
```
This fetches live currency exchange rates. The JSON response is parsed directly into a DataFrame.

### 4.2 Working with SQL
We use `mysql.connector` to interface with a MySQL database.

**Setting up the Connection:**
```python
import mysql.connector
conn = mysql.connector.connect(host='localhost', user='root', password='', database='world')
```
This establishes a session with the database server.

**Executing Queries:**
```python
df = pd.read_sql_query("SELECT * FROM countrylanguage", conn)
```
Pandas executes the SQL query and converts the result set (rows and columns) into a DataFrame, preserving column names and data types where possible.

## 5. Summary
This module equips you with the skills to step outside the world of static files and interact with the dynamic systems (APIs and Databases) that power the real world.
