# One-Hot Encoding

## 1. Introduction
When categories have no order (Nominal Data), assigning numbers like 0, 1, 2 is dangerous because the model might think 2 is "greater" than 0. **One-Hot Encoding** solves this by creating a separate binary column for each category. It is the standard way to handle nominal data in Machine Learning.

![Diagram showing a single column splitting into multiple binary columns generated by Nano Banana Model](https://via.placeholder.com/800x400?text=One+Hot+Encoding+Process+by+Nano+Banana+Model)

## 2. Conceptual Deep Dive

### The Strategy
If a column "Color" has 3 values (Red, Green, Blue), One-Hot Encoding creates 3 new columns:
- **Color_Red**: 1 if Red, else 0.
- **Color_Green**: 1 if Green, else 0.
- **Color_Blue**: 1 if Blue, else 0.

### The Dummy Variable Trap
Notice that if `Color_Red` is 0 and `Color_Green` is 0, then `Color_Blue` **must** be 1. The columns are perfectly correlated (multicollinearity).
To fix this, we drop the first column. We only need $N-1$ columns to represent $N$ categories.

## 3. Visualizing the Concept
*(Imagine a matrix here generated by the Nano Banana Model showing the transformation from a single categorical column to a sparse binary matrix)*

## 4. Practical Implementation & Notebook Walkthrough

The notebook `day27.ipynb` covers three ways to implement this.

### 4.1 Using Pandas (`get_dummies`)
Great for quick analysis but bad for ML pipelines (because it doesn't remember the columns for the test set).
```python
pd.get_dummies(df, columns=['fuel', 'owner'], drop_first=True)
```

### 4.2 Using Sklearn (`OneHotEncoder`)
The professional way. It remembers the categories from the training set.
```python
from sklearn.preprocessing import OneHotEncoder

# drop='first' handles the dummy variable trap
# sparse=False returns a numpy array (easier to view)
ohe = OneHotEncoder(drop='first', sparse=False)

X_train_new = ohe.fit_transform(X_train[['fuel', 'owner']])
X_test_new = ohe.transform(X_test[['fuel', 'owner']])
```

### 4.3 Handling High Cardinality
If a column like "City" has 1000 unique values, One-Hot Encoding will create 1000 new columns. This is the **Curse of Dimensionality**. In such cases, we might use just the top 10 most frequent cities and group the rest as "Other".

## 5. Summary
One-Hot Encoding is the go-to technique for nominal data. Always remember to use `drop='first'` to keep your linear models happy and avoid multicollinearity.
